{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwCxtbTObnNs"
      },
      "source": [
        "# <b>CS156 (Introduction to AI), Spring 2022</b>\n",
        "# <u><b>Homework 11 submission</b></u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5bZzSdKbnNv"
      },
      "source": [
        "### Roster Name: Austin Rivard\n",
        "### Student ID: 015044445\n",
        "### Email address: austin.rivard@sjsu.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-IQyBV_bnNw"
      },
      "source": [
        "##  <u>References and sources </u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R78zD5RbnNx"
      },
      "source": [
        "Code excerpts taken from class reference notebook RL.Q-learning.taxi_game.ipynb by Dr. Yulia Newton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kIOOTiCbnNx"
      },
      "source": [
        "##  <u>Solution</u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1C7w-osbnNy"
      },
      "source": [
        "#### Load libraries and set random number generator seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ng0O9M_lbnNy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gym\n",
        "from gym import envs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ru9cqRUbbnN0"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCenVHubbnN1"
      },
      "source": [
        "#### Code the solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"FrozenLake-v0\", is_slippery=False).env\n",
        "env.seed(42)\n",
        "env.reset()\n",
        "env.render()\n",
        "\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))\n",
        "\n",
        "LEFT = 0\n",
        "DOWN = 1\n",
        "RIGHT = 2\n",
        "UP = 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To8pdDzQ72iZ",
        "outputId": "685e6e69-d365-45ab-eb2b-430a296a7c24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action Space Discrete(4)\n",
            "State Space Discrete(16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qtable = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "discount = 0.9 # discount factor\n",
        "learningrate = 0.9 # learning rate\n",
        "epsilon = 0.3 # threshold of stochasticity\n",
        "for episode in range(1,10001):\n",
        "    done = False\n",
        "    reward_total = 0\n",
        "    state = env.reset()\n",
        "    while done != True:\n",
        "        explore_eploit = np.random.uniform(0, 1)\n",
        "        if explore_eploit < epsilon:\n",
        "            action = env.action_space.sample() # explore action space\n",
        "        else:\n",
        "            action = np.argmax(qtable[state]) # exploit learned values\n",
        "        \n",
        "        state_new, reward, done, info = env.step(action) #take the action\n",
        "        qtable[state,action] += learningrate * (reward + discount * np.max(qtable[state_new,:]) - qtable[state,action]) #Update Q-matrix using Bellman equation\n",
        "        reward_total = reward_total + reward\n",
        "        state = state_new   \n",
        "    if episode % 500 == 0:\n",
        "        print('Episode {} Total Reward: {}'.format(episode,reward_total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY6zxb137_yK",
        "outputId": "8eee4cfe-35e0-4d2d-bbe2-b1aa8b8ee6c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 500 Total Reward: 0.0\n",
            "Episode 1000 Total Reward: 0.0\n",
            "Episode 1500 Total Reward: 0.0\n",
            "Episode 2000 Total Reward: 0.0\n",
            "Episode 2500 Total Reward: 0.0\n",
            "Episode 3000 Total Reward: 0.0\n",
            "Episode 3500 Total Reward: 1.0\n",
            "Episode 4000 Total Reward: 1.0\n",
            "Episode 4500 Total Reward: 1.0\n",
            "Episode 5000 Total Reward: 0.0\n",
            "Episode 5500 Total Reward: 1.0\n",
            "Episode 6000 Total Reward: 1.0\n",
            "Episode 6500 Total Reward: 1.0\n",
            "Episode 7000 Total Reward: 1.0\n",
            "Episode 7500 Total Reward: 0.0\n",
            "Episode 8000 Total Reward: 1.0\n",
            "Episode 8500 Total Reward: 0.0\n",
            "Episode 9000 Total Reward: 1.0\n",
            "Episode 9500 Total Reward: 0.0\n",
            "Episode 10000 Total Reward: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qtable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iQQgnmjDiuj",
        "outputId": "33fed571-cc7b-4bc4-b1fb-c2870f015bc1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.531441  , 0.59049   , 0.59049   , 0.531441  ],\n",
              "       [0.531441  , 0.        , 0.6561    , 0.59049   ],\n",
              "       [0.59049   , 0.729     , 0.59049   , 0.6561    ],\n",
              "       [0.6561    , 0.        , 0.5845851 , 0.53144078],\n",
              "       [0.59049   , 0.6561    , 0.        , 0.531441  ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.81      , 0.        , 0.6561    ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.6561    , 0.        , 0.729     , 0.59049   ],\n",
              "       [0.6561    , 0.81      , 0.81      , 0.        ],\n",
              "       [0.729     , 0.9       , 0.        , 0.729     ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.81      , 0.9       , 0.729     ],\n",
              "       [0.81      , 0.9       , 1.        , 0.81      ],\n",
              "       [0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward_total = 0\n",
        "state= env.reset()\n",
        "env.render()\n",
        "done = False\n",
        "while not done: \n",
        "    action = np.argmax(qtable[state])\n",
        "    state, reward, done, info = env.step(action) #take step using selected action\n",
        "    reward_total = reward_total + reward\n",
        "    env.render()\n",
        "#Print the reward of these actions\n",
        "print(\"Total reward is %r\" % reward_total)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRIrddyr_Cq8",
        "outputId": "7abf3204-8f95-44d7-da8e-d30645e824a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Total reward is 1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Assignment11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}